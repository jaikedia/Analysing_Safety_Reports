{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"base.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"KzHqIcGKMXWX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621409580587,"user_tz":-330,"elapsed":17697,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"5c5abfbb-1f6c-4bdc-c0e6-9d0799b8b180"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OBOKC9LmL-D9","executionInfo":{"status":"ok","timestamp":1621410955508,"user_tz":-330,"elapsed":946,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding, LSTM\n","from keras.layers import Conv1D, Flatten, MaxPooling1D\n","from keras.preprocessing import text, sequence\n","#import wandb\n","#from wandb.keras import WandbCallback\n","import numpy as np\n","from sklearn.metrics import classification_report\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"05kcW2-rL-Eu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621411115885,"user_tz":-330,"elapsed":157117,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"7a49c4e4-e626-4418-d1ac-a7322240073f"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-1.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-1.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 55ms/step - loss: 1.0263 - accuracy: 0.5190\n","Epoch 2/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.8429 - accuracy: 0.6020\n","Epoch 3/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.6910 - accuracy: 0.7117\n","Epoch 4/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.5781 - accuracy: 0.7792\n","Epoch 5/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4983 - accuracy: 0.8153\n","Epoch 6/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4395 - accuracy: 0.8389\n","Epoch 7/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4043 - accuracy: 0.8526\n","Epoch 8/10\n","282/282 [==============================] - 16s 55ms/step - loss: 0.3678 - accuracy: 0.8691\n","Epoch 9/10\n","282/282 [==============================] - 16s 55ms/step - loss: 0.3410 - accuracy: 0.8772\n","Epoch 10/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3263 - accuracy: 0.8817\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.92      0.94      2136\n","           1       0.87      0.91      0.89      2221\n","           2       0.94      0.94      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.92      0.92      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.76      0.78       237\n","           1       0.62      0.64      0.63       247\n","           2       0.78      0.79      0.79       516\n","\n","    accuracy                           0.74      1000\n","   macro avg       0.73      0.73      0.73      1000\n","weighted avg       0.75      0.74      0.75      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.77      0.79       571\n","           1       0.61      0.61      0.61       595\n","           2       0.77      0.79      0.78      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.73      0.72      0.73      2409\n","weighted avg       0.74      0.74      0.74      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLp8UGE8naH-","executionInfo":{"status":"ok","timestamp":1621411266694,"user_tz":-330,"elapsed":301720,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"738f3cb2-e740-435d-caf5-9b3dcd5ec77d"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-2.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-2.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 52ms/step - loss: 1.0019 - accuracy: 0.5299\n","Epoch 2/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.8119 - accuracy: 0.6463\n","Epoch 3/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.6484 - accuracy: 0.7475\n","Epoch 4/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.5419 - accuracy: 0.7974\n","Epoch 5/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4693 - accuracy: 0.8204\n","Epoch 6/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4338 - accuracy: 0.8411\n","Epoch 7/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3894 - accuracy: 0.8532\n","Epoch 8/10\n","282/282 [==============================] - 15s 51ms/step - loss: 0.3670 - accuracy: 0.8744\n","Epoch 9/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3293 - accuracy: 0.8791\n","Epoch 10/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3228 - accuracy: 0.8827\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.94      0.94      2136\n","           1       0.84      0.95      0.89      2221\n","           2       0.97      0.91      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.92      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.76      0.77       237\n","           1       0.58      0.68      0.63       247\n","           2       0.80      0.74      0.77       516\n","\n","    accuracy                           0.73      1000\n","   macro avg       0.72      0.73      0.72      1000\n","weighted avg       0.74      0.73      0.73      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.80      0.79       571\n","           1       0.55      0.67      0.60       595\n","           2       0.81      0.71      0.76      1243\n","\n","    accuracy                           0.72      2409\n","   macro avg       0.71      0.73      0.71      2409\n","weighted avg       0.74      0.72      0.73      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyD7dGI7naUc","executionInfo":{"status":"ok","timestamp":1621411493490,"user_tz":-330,"elapsed":148178,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"91e773da-131d-45ea-d1fe-ae8c78c574f0"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-3.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-3.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 50ms/step - loss: 1.0296 - accuracy: 0.5044\n","Epoch 2/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.8357 - accuracy: 0.6065\n","Epoch 3/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.6580 - accuracy: 0.7450\n","Epoch 4/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.5401 - accuracy: 0.7968\n","Epoch 5/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4693 - accuracy: 0.8254\n","Epoch 6/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4268 - accuracy: 0.8445\n","Epoch 7/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4127 - accuracy: 0.8494\n","Epoch 8/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3738 - accuracy: 0.8628\n","Epoch 9/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3357 - accuracy: 0.8822\n","Epoch 10/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3220 - accuracy: 0.8773\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.94      0.94      2136\n","           1       0.86      0.94      0.90      2221\n","           2       0.97      0.93      0.95      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.83      0.82       237\n","           1       0.62      0.71      0.66       247\n","           2       0.84      0.78      0.81       516\n","\n","    accuracy                           0.77      1000\n","   macro avg       0.76      0.77      0.76      1000\n","weighted avg       0.78      0.77      0.78      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.80      0.79       571\n","           1       0.61      0.69      0.64       595\n","           2       0.81      0.75      0.78      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.73      0.75      0.74      2409\n","weighted avg       0.76      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iCkfZpDnaeB","executionInfo":{"status":"ok","timestamp":1621411646362,"user_tz":-330,"elapsed":295869,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"416fabf9-a6b4-41e0-a8df-117a33a3f755"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-4.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-4.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 53ms/step - loss: 1.0186 - accuracy: 0.5277\n","Epoch 2/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.8170 - accuracy: 0.6232\n","Epoch 3/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.6493 - accuracy: 0.7417\n","Epoch 4/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.5417 - accuracy: 0.7946\n","Epoch 5/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4992 - accuracy: 0.8164\n","Epoch 6/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4400 - accuracy: 0.8354\n","Epoch 7/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3878 - accuracy: 0.8629\n","Epoch 8/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3600 - accuracy: 0.8688\n","Epoch 9/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3266 - accuracy: 0.8791\n","Epoch 10/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3216 - accuracy: 0.8800\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95      2136\n","           1       0.88      0.94      0.91      2221\n","           2       0.95      0.94      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.94      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.72      0.77       237\n","           1       0.65      0.73      0.68       247\n","           2       0.82      0.81      0.81       516\n","\n","    accuracy                           0.77      1000\n","   macro avg       0.76      0.75      0.75      1000\n","weighted avg       0.77      0.77      0.77      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.78      0.80       571\n","           1       0.61      0.65      0.63       595\n","           2       0.79      0.78      0.79      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.74      0.74      2409\n","weighted avg       0.75      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RoHASzXnam_","executionInfo":{"status":"ok","timestamp":1621411796550,"user_tz":-330,"elapsed":256884,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"05455775-dde6-48d0-9753-03dbded63b69"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-5.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-5.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 52ms/step - loss: 1.0177 - accuracy: 0.5113\n","Epoch 2/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.7975 - accuracy: 0.6484\n","Epoch 3/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.6339 - accuracy: 0.7450\n","Epoch 4/10\n","282/282 [==============================] - 15s 51ms/step - loss: 0.5518 - accuracy: 0.7949\n","Epoch 5/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4795 - accuracy: 0.8210\n","Epoch 6/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4268 - accuracy: 0.8443\n","Epoch 7/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3781 - accuracy: 0.8651\n","Epoch 8/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3633 - accuracy: 0.8670\n","Epoch 9/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3313 - accuracy: 0.8851\n","Epoch 10/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3007 - accuracy: 0.8936\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.91      0.94      2136\n","           1       0.84      0.95      0.89      2221\n","           2       0.96      0.93      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.93      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.75      0.80       237\n","           1       0.57      0.65      0.61       247\n","           2       0.77      0.77      0.77       516\n","\n","    accuracy                           0.73      1000\n","   macro avg       0.74      0.72      0.73      1000\n","weighted avg       0.74      0.73      0.74      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.74      0.78       571\n","           1       0.57      0.67      0.62       595\n","           2       0.78      0.76      0.77      1243\n","\n","    accuracy                           0.73      2409\n","   macro avg       0.73      0.72      0.72      2409\n","weighted avg       0.74      0.73      0.73      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wC79hBTpnavZ","executionInfo":{"status":"ok","timestamp":1621411955304,"user_tz":-330,"elapsed":158735,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"b2848ea1-4bb6-44b1-fd83-59dbc3dbfa40"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-6.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-6.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 55ms/step - loss: 1.0244 - accuracy: 0.5127\n","Epoch 2/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.8352 - accuracy: 0.6010\n","Epoch 3/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.6812 - accuracy: 0.7259\n","Epoch 4/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.5410 - accuracy: 0.7933\n","Epoch 5/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.4669 - accuracy: 0.8388\n","Epoch 6/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4478 - accuracy: 0.8421\n","Epoch 7/10\n","282/282 [==============================] - 16s 55ms/step - loss: 0.3917 - accuracy: 0.8609\n","Epoch 8/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3642 - accuracy: 0.8743\n","Epoch 9/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3415 - accuracy: 0.8798\n","Epoch 10/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3067 - accuracy: 0.8898\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.94      0.94      2135\n","           1       0.88      0.93      0.90      2222\n","           2       0.96      0.94      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.93      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.80      0.79       238\n","           1       0.63      0.63      0.63       246\n","           2       0.80      0.80      0.80       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.74      0.74      0.74      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.80      0.79       571\n","           1       0.61      0.64      0.62       595\n","           2       0.80      0.77      0.78      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.73      0.74      0.73      2409\n","weighted avg       0.75      0.74      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFGOd1Puna3M","executionInfo":{"status":"ok","timestamp":1621412108329,"user_tz":-330,"elapsed":311752,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"e4812503-afb4-47f3-e701-baacb954e0b2"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-7.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-7.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 54ms/step - loss: 1.0257 - accuracy: 0.5052\n","Epoch 2/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.8001 - accuracy: 0.6449\n","Epoch 3/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.6234 - accuracy: 0.7517\n","Epoch 4/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.5404 - accuracy: 0.7938\n","Epoch 5/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4772 - accuracy: 0.8210\n","Epoch 6/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4029 - accuracy: 0.8512\n","Epoch 7/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3871 - accuracy: 0.8564\n","Epoch 8/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3524 - accuracy: 0.8708\n","Epoch 9/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3308 - accuracy: 0.8784\n","Epoch 10/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3033 - accuracy: 0.8844\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.94      0.94      2136\n","           1       0.87      0.93      0.90      2221\n","           2       0.96      0.93      0.95      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.73      0.75       237\n","           1       0.65      0.63      0.64       247\n","           2       0.78      0.81      0.79       516\n","\n","    accuracy                           0.75      1000\n","   macro avg       0.74      0.72      0.73      1000\n","weighted avg       0.75      0.75      0.75      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.79      0.77       571\n","           1       0.61      0.63      0.62       595\n","           2       0.78      0.76      0.77      1243\n","\n","    accuracy                           0.73      2409\n","   macro avg       0.72      0.72      0.72      2409\n","weighted avg       0.73      0.73      0.73      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mf4n-pQdna_A","executionInfo":{"status":"ok","timestamp":1621412253574,"user_tz":-330,"elapsed":456993,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"54b36abf-81cc-4fe7-f3ec-17ccf5c9ef42"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-8.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-8.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 50ms/step - loss: 1.0234 - accuracy: 0.5046\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.8013 - accuracy: 0.6314\n","Epoch 3/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.6369 - accuracy: 0.7469\n","Epoch 4/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.5378 - accuracy: 0.7924\n","Epoch 5/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4748 - accuracy: 0.8274\n","Epoch 6/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4346 - accuracy: 0.8340\n","Epoch 7/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3965 - accuracy: 0.8564\n","Epoch 8/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3692 - accuracy: 0.8645\n","Epoch 9/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3251 - accuracy: 0.8843\n","Epoch 10/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3043 - accuracy: 0.8885\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.95      2136\n","           1       0.89      0.90      0.90      2221\n","           2       0.94      0.95      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.93      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.77      0.76       237\n","           1       0.67      0.65      0.66       247\n","           2       0.80      0.81      0.81       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.74      0.74      0.74      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.79      0.80       571\n","           1       0.63      0.60      0.62       595\n","           2       0.78      0.81      0.79      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.73      0.74      2409\n","weighted avg       0.75      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MLl0ZrunbF1","executionInfo":{"status":"ok","timestamp":1621412410739,"user_tz":-330,"elapsed":614154,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"b4d05a48-1db7-410b-d3c0-4f80ed254ca8"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-9.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-9.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 55ms/step - loss: 1.0441 - accuracy: 0.4951\n","Epoch 2/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.8360 - accuracy: 0.6123\n","Epoch 3/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.6514 - accuracy: 0.7368\n","Epoch 4/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.5287 - accuracy: 0.8037\n","Epoch 5/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4826 - accuracy: 0.8214\n","Epoch 6/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4535 - accuracy: 0.8297\n","Epoch 7/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3903 - accuracy: 0.8546\n","Epoch 8/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3605 - accuracy: 0.8688\n","Epoch 9/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3348 - accuracy: 0.8840\n","Epoch 10/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3072 - accuracy: 0.8899\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.95      2135\n","           1       0.79      0.97      0.87      2221\n","           2       0.98      0.89      0.93      4644\n","\n","    accuracy                           0.92      9000\n","   macro avg       0.91      0.93      0.92      9000\n","weighted avg       0.93      0.92      0.92      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.69      0.74       238\n","           1       0.51      0.77      0.61       247\n","           2       0.81      0.67      0.74       515\n","\n","    accuracy                           0.70      1000\n","   macro avg       0.71      0.71      0.70      1000\n","weighted avg       0.74      0.70      0.71      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.78      0.80       571\n","           1       0.54      0.74      0.63       595\n","           2       0.82      0.70      0.75      1243\n","\n","    accuracy                           0.73      2409\n","   macro avg       0.73      0.74      0.73      2409\n","weighted avg       0.75      0.73      0.73      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTfA9fRlnbOD","executionInfo":{"status":"ok","timestamp":1621412556144,"user_tz":-330,"elapsed":759555,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"673c07c0-a873-444f-8309-9a713c1f0e88"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-10.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-10.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 50ms/step - loss: 1.0337 - accuracy: 0.5087\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.8253 - accuracy: 0.6190\n","Epoch 3/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.6556 - accuracy: 0.7354\n","Epoch 4/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.5565 - accuracy: 0.7903\n","Epoch 5/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4916 - accuracy: 0.8197\n","Epoch 6/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4509 - accuracy: 0.8335\n","Epoch 7/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3891 - accuracy: 0.8585\n","Epoch 8/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3520 - accuracy: 0.8795\n","Epoch 9/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3416 - accuracy: 0.8721\n","Epoch 10/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3091 - accuracy: 0.8896\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.95      2135\n","           1       0.84      0.94      0.89      2222\n","           2       0.96      0.92      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.70      0.75       238\n","           1       0.58      0.68      0.63       246\n","           2       0.79      0.77      0.78       516\n","\n","    accuracy                           0.73      1000\n","   macro avg       0.72      0.72      0.72      1000\n","weighted avg       0.74      0.73      0.73      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.78      0.79       571\n","           1       0.58      0.68      0.63       595\n","           2       0.80      0.74      0.77      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.73      0.74      0.73      2409\n","weighted avg       0.75      0.74      0.74      2409\n","\n"],"name":"stdout"}]}]}