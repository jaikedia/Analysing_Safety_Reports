{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"stop.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"KzHqIcGKMXWX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621412707674,"user_tz":-330,"elapsed":20719,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"ae02306d-436d-4ef1-a88c-ad082c7d92be"},"source":["  from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OBOKC9LmL-D9","executionInfo":{"status":"ok","timestamp":1621412715584,"user_tz":-330,"elapsed":3084,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding, LSTM\n","from keras.layers import Conv1D, Flatten, MaxPooling1D\n","from keras.preprocessing import text, sequence\n","#import wandb\n","#from wandb.keras import WandbCallback\n","import numpy as np\n","from sklearn.metrics import classification_report\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"05kcW2-rL-Eu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621412897499,"user_tz":-330,"elapsed":184986,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"b2ef5737-f48e-44c8-ff16-36b65dd71cde"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-1.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-1.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 47s 50ms/step - loss: 1.0211 - accuracy: 0.5081\n","Epoch 2/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.8239 - accuracy: 0.6325\n","Epoch 3/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.6466 - accuracy: 0.7421\n","Epoch 4/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.5343 - accuracy: 0.7917\n","Epoch 5/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4834 - accuracy: 0.8214\n","Epoch 6/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4153 - accuracy: 0.8537\n","Epoch 7/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3805 - accuracy: 0.8635\n","Epoch 8/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3362 - accuracy: 0.8794\n","Epoch 9/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3252 - accuracy: 0.8863\n","Epoch 10/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.2871 - accuracy: 0.8955\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95      2136\n","           1       0.85      0.94      0.89      2221\n","           2       0.96      0.93      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.80      0.82       237\n","           1       0.62      0.69      0.66       247\n","           2       0.82      0.80      0.81       516\n","\n","    accuracy                           0.77      1000\n","   macro avg       0.76      0.76      0.76      1000\n","weighted avg       0.78      0.77      0.77      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.79      0.81       571\n","           1       0.59      0.65      0.62       595\n","           2       0.79      0.77      0.78      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.74      0.74      0.73      2409\n","weighted avg       0.75      0.74      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLp8UGE8naH-","executionInfo":{"status":"ok","timestamp":1621413045949,"user_tz":-330,"elapsed":333430,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"6b13deac-8e00-403c-95c7-b8a160d4234c"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-2.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-2.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 52ms/step - loss: 1.0346 - accuracy: 0.5122\n","Epoch 2/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.8200 - accuracy: 0.6418\n","Epoch 3/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.6197 - accuracy: 0.7484\n","Epoch 4/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.5386 - accuracy: 0.7958\n","Epoch 5/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4542 - accuracy: 0.8385\n","Epoch 6/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4254 - accuracy: 0.8499\n","Epoch 7/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3985 - accuracy: 0.8569\n","Epoch 8/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3478 - accuracy: 0.8752\n","Epoch 9/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3053 - accuracy: 0.8902\n","Epoch 10/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3024 - accuracy: 0.8924\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95      2136\n","           1       0.86      0.94      0.90      2221\n","           2       0.96      0.94      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.80      0.81       237\n","           1       0.62      0.66      0.64       247\n","           2       0.80      0.79      0.79       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.75      0.75      0.75      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.81      0.82       571\n","           1       0.58      0.67      0.62       595\n","           2       0.81      0.76      0.78      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.74      0.74      2409\n","weighted avg       0.76      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyD7dGI7naUc","executionInfo":{"status":"ok","timestamp":1621413190364,"user_tz":-330,"elapsed":477837,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"d2385e4d-4425-4953-b5b2-04febe2b9b0a"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-3.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-3.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 50ms/step - loss: 1.0155 - accuracy: 0.5139\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.8208 - accuracy: 0.6280\n","Epoch 3/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.6175 - accuracy: 0.7532\n","Epoch 4/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.5127 - accuracy: 0.8066\n","Epoch 5/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4587 - accuracy: 0.8275\n","Epoch 6/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.4091 - accuracy: 0.8501\n","Epoch 7/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3623 - accuracy: 0.8670\n","Epoch 8/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3341 - accuracy: 0.8820\n","Epoch 9/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3102 - accuracy: 0.8868\n","Epoch 10/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.2961 - accuracy: 0.8915\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.94      0.95      2136\n","           1       0.85      0.95      0.90      2221\n","           2       0.97      0.93      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.83      0.84       237\n","           1       0.61      0.71      0.66       247\n","           2       0.84      0.78      0.81       516\n","\n","    accuracy                           0.78      1000\n","   macro avg       0.77      0.77      0.77      1000\n","weighted avg       0.79      0.78      0.78      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.81      0.80       571\n","           1       0.57      0.69      0.63       595\n","           2       0.82      0.74      0.78      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.73      0.74      0.74      2409\n","weighted avg       0.75      0.74      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iCkfZpDnaeB","executionInfo":{"status":"ok","timestamp":1621413334593,"user_tz":-330,"elapsed":622060,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"655ec8b7-5560-4e25-d1d8-2ca0c665e2ef"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-4.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-4.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 50ms/step - loss: 1.0152 - accuracy: 0.5186\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.7949 - accuracy: 0.6341\n","Epoch 3/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.6266 - accuracy: 0.7379\n","Epoch 4/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.5313 - accuracy: 0.7970\n","Epoch 5/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.4612 - accuracy: 0.8268\n","Epoch 6/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.4083 - accuracy: 0.8519\n","Epoch 7/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3826 - accuracy: 0.8601\n","Epoch 8/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3466 - accuracy: 0.8790\n","Epoch 9/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3101 - accuracy: 0.8919\n","Epoch 10/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3146 - accuracy: 0.8841\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95      2136\n","           1       0.85      0.95      0.90      2221\n","           2       0.97      0.93      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.76      0.78       237\n","           1       0.62      0.75      0.68       247\n","           2       0.83      0.77      0.80       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.75      0.76      0.75      1000\n","weighted avg       0.77      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.81      0.81       571\n","           1       0.58      0.70      0.64       595\n","           2       0.82      0.75      0.78      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.75      0.74      2409\n","weighted avg       0.76      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RoHASzXnam_","executionInfo":{"status":"ok","timestamp":1621413481321,"user_tz":-330,"elapsed":768782,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"7098f253-269c-4092-a203-d7ad3315d191"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-5.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-5.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 51ms/step - loss: 1.0158 - accuracy: 0.5194\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.7874 - accuracy: 0.6554\n","Epoch 3/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.6261 - accuracy: 0.7562\n","Epoch 4/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.5213 - accuracy: 0.8046\n","Epoch 5/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.4623 - accuracy: 0.8340\n","Epoch 6/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4112 - accuracy: 0.8494\n","Epoch 7/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3829 - accuracy: 0.8625\n","Epoch 8/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3520 - accuracy: 0.8762\n","Epoch 9/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3103 - accuracy: 0.8840\n","Epoch 10/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3044 - accuracy: 0.8910\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.94      0.95      2136\n","           1       0.86      0.94      0.90      2221\n","           2       0.96      0.93      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.83      0.82       237\n","           1       0.62      0.68      0.64       247\n","           2       0.81      0.76      0.78       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.74      0.76      0.75      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.83      0.80       571\n","           1       0.61      0.65      0.63       595\n","           2       0.81      0.76      0.79      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.73      0.75      0.74      2409\n","weighted avg       0.75      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wC79hBTpnavZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413629329,"user_tz":-330,"elapsed":916788,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"3819ecd4-c33b-4825-99c5-c6d321b31543"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-6.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-6.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 51ms/step - loss: 1.0179 - accuracy: 0.5199\n","Epoch 2/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.7759 - accuracy: 0.6540\n","Epoch 3/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.6132 - accuracy: 0.7631\n","Epoch 4/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.5204 - accuracy: 0.8098\n","Epoch 5/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4512 - accuracy: 0.8347\n","Epoch 6/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.4044 - accuracy: 0.8561\n","Epoch 7/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3631 - accuracy: 0.8740\n","Epoch 8/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3538 - accuracy: 0.8716\n","Epoch 9/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3070 - accuracy: 0.8878\n","Epoch 10/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.2886 - accuracy: 0.8999\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.93      0.95      2135\n","           1       0.87      0.94      0.90      2222\n","           2       0.96      0.94      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.94      0.94      0.94      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.76      0.80       238\n","           1       0.62      0.65      0.64       246\n","           2       0.79      0.81      0.80       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.75      0.74      0.75      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.79      0.81       571\n","           1       0.60      0.65      0.63       595\n","           2       0.79      0.78      0.79      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.74      0.74      2409\n","weighted avg       0.76      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qFGOd1Puna3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413772089,"user_tz":-330,"elapsed":1059545,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"959fd00c-49c9-43d1-a1cf-8f8d0b3aee3e"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-7.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-7.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 14s 49ms/step - loss: 1.0160 - accuracy: 0.5182\n","Epoch 2/10\n","282/282 [==============================] - 13s 48ms/step - loss: 0.7811 - accuracy: 0.6579\n","Epoch 3/10\n","282/282 [==============================] - 13s 48ms/step - loss: 0.6027 - accuracy: 0.7583\n","Epoch 4/10\n","282/282 [==============================] - 14s 48ms/step - loss: 0.5207 - accuracy: 0.8065\n","Epoch 5/10\n","282/282 [==============================] - 14s 48ms/step - loss: 0.4547 - accuracy: 0.8333\n","Epoch 6/10\n","282/282 [==============================] - 14s 48ms/step - loss: 0.4079 - accuracy: 0.8492\n","Epoch 7/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3882 - accuracy: 0.8579\n","Epoch 8/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3360 - accuracy: 0.8780\n","Epoch 9/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3145 - accuracy: 0.8829\n","Epoch 10/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.2839 - accuracy: 0.9025\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.93      0.95      2136\n","           1       0.89      0.90      0.90      2221\n","           2       0.94      0.96      0.95      4643\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.94      0.93      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.73      0.79       237\n","           1       0.66      0.59      0.62       247\n","           2       0.76      0.85      0.80       516\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.76      0.72      0.74      1000\n","weighted avg       0.76      0.76      0.75      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.78      0.81       571\n","           1       0.61      0.61      0.61       595\n","           2       0.78      0.81      0.79      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.73      0.74      2409\n","weighted avg       0.75      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mf4n-pQdna_A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621413924988,"user_tz":-330,"elapsed":1212442,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"9b09ced4-c6ad-44b5-ae03-c69bea728e57"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-8.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-8.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 15s 52ms/step - loss: 1.0089 - accuracy: 0.5190\n","Epoch 2/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.7687 - accuracy: 0.6536\n","Epoch 3/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.6353 - accuracy: 0.7461\n","Epoch 4/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.5241 - accuracy: 0.7992\n","Epoch 5/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4478 - accuracy: 0.8390\n","Epoch 6/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4064 - accuracy: 0.8505\n","Epoch 7/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3860 - accuracy: 0.8630\n","Epoch 8/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3413 - accuracy: 0.8760\n","Epoch 9/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.3294 - accuracy: 0.8849\n","Epoch 10/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.3092 - accuracy: 0.8880\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.94      0.95      2136\n","           1       0.84      0.96      0.89      2221\n","           2       0.97      0.92      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.94      0.93      9000\n","weighted avg       0.94      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.80      0.76       237\n","           1       0.61      0.66      0.63       247\n","           2       0.82      0.75      0.79       516\n","\n","    accuracy                           0.74      1000\n","   macro avg       0.72      0.74      0.73      1000\n","weighted avg       0.75      0.74      0.74      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.83      0.81       571\n","           1       0.58      0.68      0.62       595\n","           2       0.81      0.72      0.76      1243\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.72      0.74      0.73      2409\n","weighted avg       0.75      0.74      0.74      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7MLl0ZrunbF1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414073994,"user_tz":-330,"elapsed":1361446,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"2ab062c3-e94f-48f0-c6c6-816139a3d4e8"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-9.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-9.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 53ms/step - loss: 1.0103 - accuracy: 0.5247\n","Epoch 2/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.7844 - accuracy: 0.6491\n","Epoch 3/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.5954 - accuracy: 0.7675\n","Epoch 4/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.5184 - accuracy: 0.7977\n","Epoch 5/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.4568 - accuracy: 0.8279\n","Epoch 6/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4049 - accuracy: 0.8565\n","Epoch 7/10\n","282/282 [==============================] - 14s 51ms/step - loss: 0.3661 - accuracy: 0.8657\n","Epoch 8/10\n","282/282 [==============================] - 14s 49ms/step - loss: 0.3424 - accuracy: 0.8766\n","Epoch 9/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3118 - accuracy: 0.8872\n","Epoch 10/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.2835 - accuracy: 0.8991\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.94      0.95      2135\n","           1       0.91      0.89      0.90      2221\n","           2       0.94      0.96      0.95      4644\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.94      0.93      0.93      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.71      0.77       238\n","           1       0.65      0.64      0.64       247\n","           2       0.78      0.84      0.81       515\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.75      0.73      0.74      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.81      0.82       571\n","           1       0.66      0.60      0.63       595\n","           2       0.78      0.83      0.80      1243\n","\n","    accuracy                           0.77      2409\n","   macro avg       0.76      0.75      0.75      2409\n","weighted avg       0.76      0.77      0.77      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GTfA9fRlnbOD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414219929,"user_tz":-330,"elapsed":1507379,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"758ac1c4-8f1a-4a54-8932-746450d134ed"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-10.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-10.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(old)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(old)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(old)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 14s 49ms/step - loss: 1.0230 - accuracy: 0.5176\n","Epoch 2/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.7812 - accuracy: 0.6515\n","Epoch 3/10\n","282/282 [==============================] - 15s 53ms/step - loss: 0.6122 - accuracy: 0.7570\n","Epoch 4/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.5254 - accuracy: 0.8069\n","Epoch 5/10\n","282/282 [==============================] - 15s 52ms/step - loss: 0.4540 - accuracy: 0.8376\n","Epoch 6/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.4083 - accuracy: 0.8507\n","Epoch 7/10\n","282/282 [==============================] - 14s 50ms/step - loss: 0.3709 - accuracy: 0.8682\n","Epoch 8/10\n","282/282 [==============================] - 13s 47ms/step - loss: 0.3245 - accuracy: 0.8838\n","Epoch 9/10\n","282/282 [==============================] - 13s 47ms/step - loss: 0.3080 - accuracy: 0.8862\n","Epoch 10/10\n","282/282 [==============================] - 13s 47ms/step - loss: 0.2863 - accuracy: 0.8949\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.93      0.95      2135\n","           1       0.82      0.97      0.89      2222\n","           2       0.98      0.91      0.94      4643\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.94      0.93      9000\n","weighted avg       0.94      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.74      0.79       238\n","           1       0.58      0.73      0.64       246\n","           2       0.82      0.76      0.79       516\n","\n","    accuracy                           0.75      1000\n","   macro avg       0.75      0.74      0.74      1000\n","weighted avg       0.77      0.75      0.75      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.79      0.81       571\n","           1       0.56      0.74      0.64       595\n","           2       0.83      0.73      0.78      1243\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.75      0.74      2409\n","weighted avg       0.77      0.75      0.75      2409\n","\n"],"name":"stdout"}]}]}