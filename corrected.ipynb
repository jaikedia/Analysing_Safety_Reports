{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"corrected.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"KzHqIcGKMXWX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414359576,"user_tz":-330,"elapsed":19754,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"1f37c508-352a-43e8-fc29-5d25605d55a2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OBOKC9LmL-D9","executionInfo":{"status":"ok","timestamp":1621414368176,"user_tz":-330,"elapsed":3333,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding, LSTM\n","from keras.layers import Conv1D, Flatten, MaxPooling1D\n","from keras.preprocessing import text, sequence\n","#import wandb\n","#from wandb.keras import WandbCallback\n","import numpy as np\n","from sklearn.metrics import classification_report\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"05kcW2-rL-Eu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621414577626,"user_tz":-330,"elapsed":212769,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"0126ef5a-2943-47ea-ed84-d31a3b4b886a"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-1.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-1.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 48s 60ms/step - loss: 0.9863 - accuracy: 0.5508\n","Epoch 2/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.7079 - accuracy: 0.6919\n","Epoch 3/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.5555 - accuracy: 0.7650\n","Epoch 4/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.4559 - accuracy: 0.8273\n","Epoch 5/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.4053 - accuracy: 0.8449\n","Epoch 6/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.3513 - accuracy: 0.8678\n","Epoch 7/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.3211 - accuracy: 0.8783\n","Epoch 8/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.3008 - accuracy: 0.8908\n","Epoch 9/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.2952 - accuracy: 0.8912\n","Epoch 10/10\n","282/282 [==============================] - 17s 60ms/step - loss: 0.2642 - accuracy: 0.8997\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.97      1881\n","           1       0.92      0.84      0.88      2183\n","           2       0.93      0.96      0.95      4936\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.94      0.93      0.93      9000\n","weighted avg       0.93      0.94      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.85      0.86       211\n","           1       0.68      0.58      0.63       239\n","           2       0.81      0.87      0.84       550\n","\n","    accuracy                           0.80      1000\n","   macro avg       0.79      0.77      0.77      1000\n","weighted avg       0.79      0.80      0.79      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.85      0.85       523\n","           1       0.63      0.52      0.57       580\n","           2       0.77      0.83      0.80      1306\n","\n","    accuracy                           0.76      2409\n","   macro avg       0.75      0.73      0.74      2409\n","weighted avg       0.76      0.76      0.76      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLp8UGE8naH-","executionInfo":{"status":"ok","timestamp":1621414744885,"user_tz":-330,"elapsed":380018,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"c78c1b3f-e90c-4302-d886-6d73ec87a0a4"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-2.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-2.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 58ms/step - loss: 0.9909 - accuracy: 0.5534\n","Epoch 2/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.7206 - accuracy: 0.6847\n","Epoch 3/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.5635 - accuracy: 0.7565\n","Epoch 4/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4556 - accuracy: 0.8249\n","Epoch 5/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.4125 - accuracy: 0.8427\n","Epoch 6/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.3676 - accuracy: 0.8600\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3393 - accuracy: 0.8694\n","Epoch 8/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3176 - accuracy: 0.8782\n","Epoch 9/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.2835 - accuracy: 0.8947\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2673 - accuracy: 0.8991\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1883\n","           1       0.85      0.92      0.88      2181\n","           2       0.97      0.92      0.94      4936\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.94      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.89      0.87       209\n","           1       0.57      0.66      0.61       241\n","           2       0.83      0.76      0.80       550\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.75      0.77      0.76      1000\n","weighted avg       0.77      0.76      0.77      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.86      0.85       523\n","           1       0.56      0.65      0.60       580\n","           2       0.82      0.76      0.79      1306\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.76      0.75      2409\n","weighted avg       0.76      0.75      0.76      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyD7dGI7naUc","executionInfo":{"status":"ok","timestamp":1621414908069,"user_tz":-330,"elapsed":543196,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"2725fbb0-ba12-4446-9fcd-a0f676ec9b5d"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-3.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-3.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 57ms/step - loss: 0.9896 - accuracy: 0.5572\n","Epoch 2/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.7050 - accuracy: 0.6944\n","Epoch 3/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.5502 - accuracy: 0.7685\n","Epoch 4/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.4576 - accuracy: 0.8124\n","Epoch 5/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.4170 - accuracy: 0.8301\n","Epoch 6/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.3526 - accuracy: 0.8657\n","Epoch 7/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.3255 - accuracy: 0.8727\n","Epoch 8/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.3085 - accuracy: 0.8854\n","Epoch 9/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.2844 - accuracy: 0.8927\n","Epoch 10/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.2712 - accuracy: 0.8987\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1882\n","           1       0.85      0.91      0.88      2187\n","           2       0.96      0.93      0.94      4931\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.90      0.90       210\n","           1       0.61      0.66      0.63       235\n","           2       0.84      0.81      0.83       555\n","\n","    accuracy                           0.80      1000\n","   macro avg       0.78      0.79      0.79      1000\n","weighted avg       0.80      0.80      0.80      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.87      0.86       523\n","           1       0.59      0.64      0.61       580\n","           2       0.81      0.78      0.80      1306\n","\n","    accuracy                           0.77      2409\n","   macro avg       0.75      0.76      0.76      2409\n","weighted avg       0.77      0.77      0.77      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iCkfZpDnaeB","executionInfo":{"status":"ok","timestamp":1621415076499,"user_tz":-330,"elapsed":711619,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"c8804a05-cc38-4ef1-9cb9-aeadcc458135"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-4.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-4.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 58ms/step - loss: 0.9808 - accuracy: 0.5516\n","Epoch 2/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.6882 - accuracy: 0.7014\n","Epoch 3/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.5266 - accuracy: 0.7827\n","Epoch 4/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4491 - accuracy: 0.8268\n","Epoch 5/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3885 - accuracy: 0.8489\n","Epoch 6/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3521 - accuracy: 0.8660\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3121 - accuracy: 0.8828\n","Epoch 8/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2883 - accuracy: 0.8947\n","Epoch 9/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2895 - accuracy: 0.8954\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2790 - accuracy: 0.8954\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1881\n","           1       0.81      0.93      0.87      2181\n","           2       0.97      0.90      0.94      4938\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.94      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.84      0.84       211\n","           1       0.59      0.77      0.67       241\n","           2       0.86      0.75      0.80       548\n","\n","    accuracy                           0.77      1000\n","   macro avg       0.77      0.79      0.77      1000\n","weighted avg       0.79      0.77      0.78      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.86      0.85       523\n","           1       0.54      0.69      0.61       580\n","           2       0.83      0.73      0.77      1306\n","\n","    accuracy                           0.74      2409\n","   macro avg       0.74      0.76      0.74      2409\n","weighted avg       0.76      0.74      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RoHASzXnam_","executionInfo":{"status":"ok","timestamp":1621415243711,"user_tz":-330,"elapsed":878825,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"a955e704-bb09-4ad8-ec15-5f296b14f6a9"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-5.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-5.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 58ms/step - loss: 0.9889 - accuracy: 0.5486\n","Epoch 2/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.6932 - accuracy: 0.6929\n","Epoch 3/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.5675 - accuracy: 0.7519\n","Epoch 4/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4549 - accuracy: 0.8143\n","Epoch 5/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4236 - accuracy: 0.8338\n","Epoch 6/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3713 - accuracy: 0.8580\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3291 - accuracy: 0.8780\n","Epoch 8/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3022 - accuracy: 0.8838\n","Epoch 9/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2966 - accuracy: 0.8875\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2700 - accuracy: 0.8989\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1883\n","           1       0.84      0.92      0.88      2171\n","           2       0.96      0.92      0.94      4946\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.93      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.85      0.86       209\n","           1       0.60      0.65      0.63       251\n","           2       0.80      0.78      0.79       540\n","\n","    accuracy                           0.76      1000\n","   macro avg       0.76      0.76      0.76      1000\n","weighted avg       0.76      0.76      0.76      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.86      0.86       523\n","           1       0.60      0.63      0.61       580\n","           2       0.81      0.79      0.80      1306\n","\n","    accuracy                           0.77      2409\n","   macro avg       0.75      0.76      0.76      2409\n","weighted avg       0.77      0.77      0.77      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wC79hBTpnavZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621415412410,"user_tz":-330,"elapsed":1047521,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"2b53d310-2176-456a-8a4d-85941d72014c"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-6.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-6.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 57ms/step - loss: 0.9701 - accuracy: 0.5606\n","Epoch 2/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.7055 - accuracy: 0.7019\n","Epoch 3/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.5823 - accuracy: 0.7464\n","Epoch 4/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4629 - accuracy: 0.8145\n","Epoch 5/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4138 - accuracy: 0.8419\n","Epoch 6/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3919 - accuracy: 0.8499\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3337 - accuracy: 0.8721\n","Epoch 8/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3153 - accuracy: 0.8765\n","Epoch 9/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.2960 - accuracy: 0.8898\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2653 - accuracy: 0.8977\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1877\n","           1       0.86      0.88      0.87      2183\n","           2       0.95      0.93      0.94      4940\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.92      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.86      0.86       215\n","           1       0.62      0.62      0.62       239\n","           2       0.81      0.82      0.81       546\n","\n","    accuracy                           0.78      1000\n","   macro avg       0.77      0.76      0.77      1000\n","weighted avg       0.78      0.78      0.78      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.86      0.86       523\n","           1       0.60      0.60      0.60       580\n","           2       0.80      0.80      0.80      1306\n","\n","    accuracy                           0.76      2409\n","   macro avg       0.75      0.75      0.75      2409\n","weighted avg       0.76      0.76      0.76      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qFGOd1Puna3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621415581449,"user_tz":-330,"elapsed":1216558,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"3b0e6733-3f8f-4909-fffa-a0a46942eb84"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-7.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-7.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.9882 - accuracy: 0.5446\n","Epoch 2/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.6919 - accuracy: 0.6967\n","Epoch 3/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.5545 - accuracy: 0.7606\n","Epoch 4/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4619 - accuracy: 0.8207\n","Epoch 5/10\n","282/282 [==============================] - 17s 59ms/step - loss: 0.4150 - accuracy: 0.8443\n","Epoch 6/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3592 - accuracy: 0.8656\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3318 - accuracy: 0.8760\n","Epoch 8/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3071 - accuracy: 0.8855\n","Epoch 9/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2816 - accuracy: 0.8926\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2585 - accuracy: 0.9039\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.97      0.98      1882\n","           1       0.89      0.86      0.87      2183\n","           2       0.93      0.96      0.94      4935\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.94      0.93      0.93      9000\n","weighted avg       0.93      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.76      0.82       210\n","           1       0.67      0.57      0.62       239\n","           2       0.78      0.87      0.83       551\n","\n","    accuracy                           0.78      1000\n","   macro avg       0.78      0.74      0.75      1000\n","weighted avg       0.78      0.78      0.77      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.80      0.84       523\n","           1       0.62      0.54      0.58       580\n","           2       0.78      0.85      0.81      1306\n","\n","    accuracy                           0.77      2409\n","   macro avg       0.76      0.73      0.74      2409\n","weighted avg       0.76      0.77      0.76      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mf4n-pQdna_A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621415747522,"user_tz":-330,"elapsed":1382629,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"97c621c5-0467-4b9b-f21c-a6aacdfed71f"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-8.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-8.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 17s 58ms/step - loss: 0.9898 - accuracy: 0.5489\n","Epoch 2/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.7190 - accuracy: 0.6876\n","Epoch 3/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.5509 - accuracy: 0.7594\n","Epoch 4/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.4539 - accuracy: 0.8249\n","Epoch 5/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.4082 - accuracy: 0.8456\n","Epoch 6/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.3686 - accuracy: 0.8648\n","Epoch 7/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.3237 - accuracy: 0.8808\n","Epoch 8/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.3123 - accuracy: 0.8832\n","Epoch 9/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.2960 - accuracy: 0.8843\n","Epoch 10/10\n","282/282 [==============================] - 16s 58ms/step - loss: 0.2891 - accuracy: 0.8872\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.99      0.98      1884\n","           1       0.80      0.94      0.86      2174\n","           2       0.97      0.89      0.93      4942\n","\n","    accuracy                           0.92      9000\n","   macro avg       0.91      0.94      0.92      9000\n","weighted avg       0.93      0.92      0.92      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.87      0.85       208\n","           1       0.59      0.69      0.63       248\n","           2       0.85      0.76      0.80       544\n","\n","    accuracy                           0.77      1000\n","   macro avg       0.75      0.77      0.76      1000\n","weighted avg       0.78      0.77      0.77      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.87      0.85       523\n","           1       0.55      0.71      0.62       580\n","           2       0.83      0.72      0.77      1306\n","\n","    accuracy                           0.75      2409\n","   macro avg       0.74      0.76      0.75      2409\n","weighted avg       0.77      0.75      0.75      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7MLl0ZrunbF1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621415910342,"user_tz":-330,"elapsed":1545447,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"fee74f98-e4ed-49ab-eb7a-2858a85c6f6b"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-9.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-9.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 56ms/step - loss: 1.0089 - accuracy: 0.5439\n","Epoch 2/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.7106 - accuracy: 0.6840\n","Epoch 3/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.5275 - accuracy: 0.7917\n","Epoch 4/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.4358 - accuracy: 0.8357\n","Epoch 5/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.3934 - accuracy: 0.8468\n","Epoch 6/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.3510 - accuracy: 0.8693\n","Epoch 7/10\n","282/282 [==============================] - 16s 57ms/step - loss: 0.3226 - accuracy: 0.8782\n","Epoch 8/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.2848 - accuracy: 0.8892\n","Epoch 9/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.2629 - accuracy: 0.8998\n","Epoch 10/10\n","282/282 [==============================] - 16s 56ms/step - loss: 0.2658 - accuracy: 0.8989\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.98      1890\n","           1       0.84      0.92      0.88      2180\n","           2       0.96      0.93      0.94      4930\n","\n","    accuracy                           0.93      9000\n","   macro avg       0.93      0.94      0.93      9000\n","weighted avg       0.94      0.93      0.93      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.74      0.80       202\n","           1       0.56      0.67      0.61       242\n","           2       0.81      0.79      0.80       556\n","\n","    accuracy                           0.75      1000\n","   macro avg       0.75      0.73      0.74      1000\n","weighted avg       0.76      0.75      0.75      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.82      0.84       523\n","           1       0.57      0.67      0.62       580\n","           2       0.82      0.77      0.79      1306\n","\n","    accuracy                           0.76      2409\n","   macro avg       0.75      0.75      0.75      2409\n","weighted avg       0.77      0.76      0.76      2409\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GTfA9fRlnbOD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621416068663,"user_tz":-330,"elapsed":1703766,"user":{"displayName":"Ajay Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqjEpak0ibTzsxxj3FcD5ecPkMHJUkeUPrJ73wqg=s64","userId":"11419622722169779908"}},"outputId":"a95ef38a-cc70-4160-fce6-c7538029f230"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/train/train-10.csv')\n","dataset2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/10-cross-valudate/test/d-10.csv')\n","\n","model = Sequential()\n","model.add(Embedding(90000, 50, input_length = 1000))\n","model.add(Dropout(0.5))\n","model.add(Conv1D(100, 3, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 4, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Conv1D(100, 5, padding = 'valid', activation = 'relu'))\n","model.add(MaxPooling1D())\n","model.add(Flatten())\n","model.add(Dense(250, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(units =3,  activation='softmax'))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","    \n","X_train = dataset[['OBS(mist-free)-2']]\n","X_train = pd.DataFrame(X_train)\n","lb_make = LabelEncoder()\n","dataset['Category-encoded'] = lb_make.fit_transform(dataset['Category(corrected)'])\n","Y_train = dataset[['Category-encoded']]\n","Y_train = pd.DataFrame(Y_train)\n","\n","X_test = dataset2[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","lb_make = LabelEncoder()\n","dataset2['Category-encoded'] = lb_make.fit_transform(dataset2['Category(corrected)'])\n","Y_test = dataset2[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, stratify = Y)\n","\n","tokenizer = text.Tokenizer(num_words=90000)\n","tokenizer.fit_on_texts(X_train['OBS(mist-free)-2'].to_list())\n","X_train1 = tokenizer.texts_to_sequences(X_train['OBS(mist-free)-2'].to_list())\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_train = sequence.pad_sequences(X_train1, maxlen=1000)\n","X_test = sequence.pad_sequences(X_test1, maxlen=1000)\n","model.fit(X_train, Y_train, batch_size=32, epochs=10)\n","\n","\n","\n","y_pred_train = model.predict(X_train)\n","predictions = np.argmax(y_pred_train, axis=-1)\n","b = (classification_report(Y_train, predictions))\n","print(b)\n","\n","y_pred = model.predict(X_test)\n","predictions = np.argmax(y_pred, axis=-1)\n","c = (classification_report(Y_test, predictions))\n","print(c)\n","\n","\n","test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/base-stop-mislabel-cases-10-trials/final(2409).csv')\n","\n","X_test = test[['OBS(mist-free)-2']]\n","X_test = pd.DataFrame(X_test)\n","\n","lb_make = LabelEncoder()\n","test['Category-encoded'] = lb_make.fit_transform(test['Category(corrected)'])\n","Y_test = test[['Category-encoded']]\n","Y_test = pd.DataFrame(Y_test)\n","\n","\n","\n","X_test1 = tokenizer.texts_to_sequences(X_test['OBS(mist-free)-2'].to_list())\n","X_test1 = sequence.pad_sequences(X_test1, maxlen=1000)\n","\n","\n","y_pred = model.predict(X_test1)\n","predictions = np.argmax(y_pred, axis=-1)\n","\n","\n","d = (classification_report(Y_test, predictions))\n","print(d)\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","282/282 [==============================] - 16s 54ms/step - loss: 0.9925 - accuracy: 0.5429\n","Epoch 2/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.6970 - accuracy: 0.6899\n","Epoch 3/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.5656 - accuracy: 0.7490\n","Epoch 4/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.4626 - accuracy: 0.8149\n","Epoch 5/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.3989 - accuracy: 0.8425\n","Epoch 6/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.3735 - accuracy: 0.8580\n","Epoch 7/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.3278 - accuracy: 0.8750\n","Epoch 8/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.2975 - accuracy: 0.8888\n","Epoch 9/10\n","282/282 [==============================] - 15s 54ms/step - loss: 0.2799 - accuracy: 0.8945\n","Epoch 10/10\n","282/282 [==============================] - 15s 55ms/step - loss: 0.2764 - accuracy: 0.8932\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98      1885\n","           1       0.87      0.91      0.89      2175\n","           2       0.96      0.93      0.95      4940\n","\n","    accuracy                           0.94      9000\n","   macro avg       0.93      0.94      0.94      9000\n","weighted avg       0.94      0.94      0.94      9000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.83      0.85       207\n","           1       0.60      0.68      0.64       247\n","           2       0.83      0.80      0.82       546\n","\n","    accuracy                           0.78      1000\n","   macro avg       0.77      0.77      0.77      1000\n","weighted avg       0.79      0.78      0.78      1000\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.86      0.86       523\n","           1       0.59      0.63      0.61       580\n","           2       0.82      0.78      0.80      1306\n","\n","    accuracy                           0.76      2409\n","   macro avg       0.75      0.76      0.75      2409\n","weighted avg       0.77      0.76      0.77      2409\n","\n"],"name":"stdout"}]}]}